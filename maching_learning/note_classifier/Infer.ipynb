{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundcard as sc\n",
    "import torchaudio as ta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from note_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_scale(data, SR=16000, NFFT=4095, N_MELS=256):\n",
    "    \"\"\" converts spectrum to MEL spectrum without using librosa/torchaudio because they're broken on Jetson\n",
    "        Note: only works with single channel\n",
    "        Arguments:\n",
    "            SR: sample rate\n",
    "            NFFT: length of FFT (except *2-1 because of implementation?)\n",
    "            N_MELS: size of output vector\n",
    "    \"\"\"\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * np.log10(1 + (SR / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, N_MELS + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = np.floor((NFFT + 1) * hz_points / SR)\n",
    "\n",
    "    fbank = np.zeros((N_MELS, int(np.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, N_MELS + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = np.dot(data, fbank.T)\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "    return filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sc.get_microphone('CODEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.play(data, samplerate=44100, channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000     # highest piano note is ~4k, shouldn't need more than double that range\n",
    "NMELS = 256    # set by the model, don't change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Audio2Midi(kernel_size=9)\n",
    "model.load_state_dict(torch.load(\"./models/300_2e-05.pth\"))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4982, 0.0000, 0.2435, 0.3251, 0.0124, 0.1755, 0.0167, 0.0000, 0.0365,\n",
      "        0.0000, 0.0434, 0.0658, 0.1043, 0.1373, 0.0000, 0.0640, 0.0000, 0.1840,\n",
      "        0.0977, 0.0535, 0.0000, 0.0404, 0.2631, 0.2547, 0.0686, 0.3259, 0.1633,\n",
      "        0.0000, 0.0635, 0.1513, 0.0000, 0.3172, 0.0000, 0.1414, 0.0662, 0.2442,\n",
      "        0.0450, 0.3463, 0.1440, 0.0330, 0.1143, 0.1568, 0.1185, 0.2823, 0.3406,\n",
      "        0.1819, 0.1308, 0.2384, 0.1711, 0.2428, 0.3526, 0.4191, 0.1851, 0.3796,\n",
      "        0.4786, 0.3701, 0.1045, 0.0000, 0.1094, 0.1937, 0.0000, 0.3853, 0.3075,\n",
      "        0.2059, 0.0000, 0.0000, 0.1132, 0.0000, 0.0000, 0.0000, 0.0000, 0.2994,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2259, 0.0000, 0.0000,\n",
      "        0.2539, 0.1695, 0.0276, 0.1263, 0.0000, 0.0000, 0.2596],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2191, 0.2942, 0.1446, 0.3489, 0.2328, 0.2045, 0.3935, 0.6198, 0.2738,\n",
      "        0.0000, 0.0000, 0.0034, 0.0970, 0.0000, 0.4029, 0.0103, 0.0000, 0.0885,\n",
      "        0.0357, 0.0918, 0.0000, 0.0000, 0.0380, 0.0076, 0.2562, 0.2730, 0.1510,\n",
      "        0.0021, 0.0000, 0.0000, 0.1202, 0.2772, 0.1736, 0.0484, 0.0339, 0.1570,\n",
      "        0.1213, 0.0774, 0.1873, 0.1072, 0.3882, 0.2850, 0.1918, 0.1259, 0.1330,\n",
      "        0.1535, 0.2420, 0.1924, 0.3484, 0.1454, 0.4743, 0.2025, 0.3646, 0.0000,\n",
      "        0.0483, 0.1161, 0.1979, 0.2308, 0.3563, 0.2600, 0.4782, 0.4816, 0.6023,\n",
      "        0.4653, 0.7178, 0.5115, 0.4443, 0.5528, 0.4172, 0.4347, 0.0699, 0.4161,\n",
      "        0.0091, 0.0625, 0.0000, 0.0000, 0.1756, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.3429, 0.1405, 0.0940, 0.4363, 0.3826, 0.3556, 0.1284],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "CPU times: user 1.99 s, sys: 100 ms, total: 2.09 s\n",
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with mic.recorder(samplerate=SR, blocksize=32) as m, sp.player(samplerate=SR, channels=2, blocksize=32) as s:\n",
    "    for j in range(SR//2048*2):\n",
    "        data = m.record(numframes=2048)\n",
    "        fframe = np.abs(np.fft.fft(data))\n",
    "        lframe = mel_scale(np.abs(fframe[:,0]))\n",
    "        rframe = mel_scale(np.abs(fframe[:,1]))\n",
    "        lout = model(torch.from_numpy(lframe).float().unsqueeze(0).unsqueeze(0).cuda())\n",
    "        rout = model(torch.from_numpy(rframe).float().unsqueeze(0).unsqueeze(0).cuda())\n",
    "        if j==0:\n",
    "            print(lout)\n",
    "            print(rout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
