{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import soundcard as sc\n",
    "import torchaudio as ta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from note_model import *\n",
    "from zach_visualization import *\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def mel_scale(data, SR=16000, NFFT=4095, N_MELS=256):\n",
    "    \"\"\" converts spectrum to MEL spectrum without using librosa/torchaudio because they're broken on Jetson\n",
    "        Note: only works with single channel\n",
    "        Arguments:\n",
    "            SR: sample rate\n",
    "            NFFT: length of FFT (except *2-1 because of implementation?)\n",
    "            N_MELS: size of output vector\n",
    "    \"\"\"\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * np.log10(1 + (SR / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, N_MELS + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = np.floor((NFFT + 1) * hz_points / SR)\n",
    "\n",
    "    fbank = np.zeros((N_MELS, int(np.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, N_MELS + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = np.dot(data, fbank.T)\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "    return filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Microphone MacBook Pro Microphone (1 channels)>\n"
     ]
    }
   ],
   "source": [
    "mic = sc.default_microphone()\n",
    "print(mic)t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "SR = 16000     # highest piano note is ~4k, shouldn't need more than double that range\n",
    "NMELS = 256    # set by the model, don't change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Audio2Midi(kernel_size=9)\n",
    "model.load_state_dict(torch.load(\"./models/300_2e-05.pth\"))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to:  /dev/cu.SLAB_USBtoUART \n",
      "...\n",
      "Connected to:  /dev/cu.SLAB_USBtoUART  !\n"
     ]
    }
   ],
   "source": [
    "c = Cube(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def make_frame(l_vec, r_vec, genre, thresh):\n",
    "    \"\"\"\n",
    "    Creates a frame for visualization stack out of left and right machine learning outputs\n",
    "    Arguments:\n",
    "        l_vec: velocity vector for left channel\n",
    "        r_vec: velocity vector for right channel\n",
    "        genre: genre to pass through to frame\n",
    "        thresh: velocity value under which to ignore note\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    pans = torch.round(63.5 + torch.clamp(r_vec / l_vec, -63, 63))\n",
    "    velocities = torch.max(torch.cat((l_vec.unsqueeze(1), r_vec.unsqueeze(1)), dim=1), dim=1).values\n",
    "    for pitch in range(velocities.shape[0]):\n",
    "        if 127 >= velocities[pitch].item() >= thresh:\n",
    "            notes.append(Note(velocities[pitch].item(), pitch, pans[pitch].item()))\n",
    "\n",
    "    frame = Frame(notes, genre)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "g = Genre('default')\n",
    "mean_val = 0;\n",
    "with mic.recorder(samplerate=SR, blocksize=32) as m:\n",
    "    #for j in range(SR//2048*10):\n",
    "    while True:\n",
    "        data = m.record(numframes=2048)\n",
    "        data /= np.max(np.abs(data))\n",
    "        fframe = np.abs(np.fft.rfft(data))\n",
    "        fframe = np.log(np.clip(fframe, 1e-5, None))\n",
    "        lframe = mel_scale(np.abs(fframe[:,0]))\n",
    "        rframe = mel_scale(np.abs(fframe[:,0]))\n",
    "        mean_val = np.mean(lframe)\n",
    "        lout = model(torch.from_numpy(lframe).float().unsqueeze(0).unsqueeze(0).cuda())\n",
    "        rout = model(torch.from_numpy(rframe).float().unsqueeze(0).unsqueeze(0).cuda())\n",
    "        f = make_frame(lout.detach(), rout.detach(), g, thresh=0.1)\n",
    "        c.process_frame(f)\n",
    "        #ipd.clear_output()\n",
    "        c.display()\n",
    "        #display(c.display_screen(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Using Raw Mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/my_base/lib/python3.7/site-packages/soundcard/coreaudio.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(self, numframes)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0mrecorded_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mrecorded_frames\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m                 \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                 \u001b[0mrecorded_frames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/my_base/lib/python3.7/site-packages/soundcard/coreaudio.py\u001b[0m in \u001b[0;36m_record_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \"\"\"\n\u001b[1;32m    839\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/my_base/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/my_base/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = Genre('default')\n",
    "mean_val = 0;\n",
    "with mic.recorder(samplerate=SR, blocksize=32) as m:\n",
    "    #for j in range(SR//2048*30):\n",
    "    while True:\n",
    "        data = m.record(numframes=2048) + 0.0001\n",
    "        data /= np.max(np.abs(data))\n",
    "        fframe = np.abs(np.fft.rfft(data))\n",
    "        fframe = np.log(np.clip(fframe, 1e-5, None))\n",
    "        lframe = mel_scale(np.abs(fframe[:,0]))\n",
    "        rframe = mel_scale(np.abs(fframe[:,0]))\n",
    "        mean_val = np.mean(lframe)\n",
    "        offset = 20\n",
    "        lout = torch.from_numpy(lframe[offset:128+offset])\n",
    "        rout = torch.from_numpy(rframe[offset:128+offset])\n",
    "        f = make_frame(lout.detach(), rout.detach(), g, thresh=10)\n",
    "        c.process_frame(f)\n",
    "        #ipd.clear_output()\n",
    "        c.display()\n",
    "        #display(c.display_screen(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "?torch.clamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 12\n",
      "i: 13\n",
      "i: 14\n",
      "i: 15\n",
      "i: 16\n",
      "i: 17\n",
      "i: 18\n",
      "i: 19\n",
      "i: 20\n",
      "i: 21\n",
      "i: 22\n",
      "i: 23\n",
      "i: 24\n",
      "i: 25\n",
      "i: 26\n",
      "i: 27\n",
      "i: 28\n",
      "i: 29\n",
      "i: 30\n",
      "i: 31\n",
      "i: 32\n",
      "i: 33\n",
      "i: 34\n",
      "i: 35\n",
      "i: 36\n",
      "i: 37\n",
      "i: 38\n",
      "i: 39\n",
      "i: 40\n",
      "i: 41\n",
      "i: 42\n",
      "i: 43\n",
      "i: 44\n",
      "i: 45\n",
      "i: 46\n",
      "i: 47\n",
      "i: 48\n",
      "i: 49\n",
      "i: 50\n",
      "i: 51\n",
      "i: 52\n",
      "i: 53\n",
      "i: 54\n",
      "i: 55\n",
      "i: 56\n",
      "i: 57\n",
      "i: 58\n",
      "i: 59\n",
      "i: 60\n",
      "i: 61\n",
      "i: 62\n",
      "i: 63\n",
      "i: 64\n",
      "i: 65\n",
      "i: 66\n",
      "i: 67\n",
      "i: 68\n",
      "i: 69\n",
      "i: 70\n",
      "i: 71\n",
      "i: 72\n",
      "i: 73\n",
      "i: 74\n",
      "i: 75\n",
      "i: 76\n",
      "i: 77\n",
      "i: 78\n",
      "i: 79\n",
      "i: 80\n",
      "i: 81\n",
      "i: 82\n",
      "i: 83\n",
      "i: 84\n",
      "i: 85\n",
      "i: 86\n",
      "i: 87\n",
      "i: 88\n",
      "i: 89\n",
      "i: 90\n",
      "i: 91\n",
      "i: 92\n",
      "i: 93\n",
      "i: 94\n",
      "i: 95\n",
      "i: 96\n",
      "i: 97\n",
      "i: 98\n",
      "i: 99\n",
      "i: 100\n",
      "i: 101\n",
      "i: 102\n",
      "i: 103\n",
      "i: 104\n",
      "i: 105\n",
      "i: 106\n",
      "i: 107\n",
      "i: 108\n",
      "i: 109\n",
      "i: 110\n",
      "i: 111\n",
      "i: 112\n",
      "i: 113\n",
      "i: 114\n",
      "i: 115\n",
      "i: 116\n",
      "i: 117\n",
      "i: 118\n",
      "i: 119\n",
      "i: 120\n",
      "i: 121\n",
      "i: 122\n",
      "i: 123\n",
      "i: 124\n",
      "i: 125\n",
      "i: 126\n"
     ]
    }
   ],
   "source": [
    "#notes = [Note(64,i,64) for i in range(0, 72+0)]\n",
    "for i in range(12, 127):\n",
    "    print(f\"i: {i}\")\n",
    "    notes = [Note(127, i, 64)]\n",
    "    f = Frame(notes, Genre('default'))\n",
    "\n",
    "    c.clear()\n",
    "    c.process_frame(f)\n",
    "    c.display()\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c.arduino.testAnimation(c.size**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_base]",
   "language": "python",
   "name": "conda-env-my_base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
