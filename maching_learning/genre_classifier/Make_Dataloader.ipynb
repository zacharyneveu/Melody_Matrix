{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Genre Classification Initial Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Setup and Installations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "!pip install tqdm\n",
    "\n",
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#%%writefile imports.py\n",
    "%matplotlib inline\n",
    "\n",
    "# Pytorch Stuff\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio as ta\n",
    "import torchaudio.functional as taf\n",
    "\n",
    "# Librosa for audio stuff/plotting spectrograms\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "from librosa.display import *\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "# Utilities\n",
    "from IPython.display import Audio\n",
    "from tqdm.auto import tqdm # progress bars\n",
    "import random\n",
    "from pathlib import Path\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#%%writefile utils.py\n",
    "#from imports import *\n",
    "\n",
    "# Shorthand amplitude->db conversion\n",
    "db = lambda x: lr.amplitude_to_db(x)\n",
    "\n",
    "def plot_spec(sig,sr=22050, channel=None):\n",
    "    \"\"\"\n",
    "    Plots spectrogram of time domain signal (numpy or tensor) with default parameters.\n",
    "    channel: selects one channel if input has multiple channels\n",
    "    \"\"\"\n",
    "    if type(sig) is torch.Tensor:\n",
    "        sig = sig.squeeze().numpy()\n",
    "    if channel != None:\n",
    "        sig = sig[:,channel].squeeze()\n",
    "    spec = db(abs(lr.stft(sig))) \n",
    "    return specshow(spec, x_axis='time', y_axis='mel', sr=sr)\n",
    "    \n",
    "    \n",
    "def cola_window(win_size, hop_len, win_type=np.hamming):\n",
    "    \"\"\"\n",
    "    Creates a window for which the COLA constraint holds\n",
    "    \"\"\"\n",
    "    w = win_type(win_size)\n",
    "    w = np.sqrt(w)\n",
    "    K = np.sqrt(hop_len / sum(pow(w,2)))\n",
    "    w = w * K\n",
    "    return w\n",
    "\n",
    "def fourier(x):\n",
    "    \"\"\"\n",
    "    Converts a time domain tensor to frequency domain and takes angle/phase form\n",
    "    \"\"\"\n",
    "    return taf.magphase(x.rfft(1))\n",
    "\n",
    "def polar_to_cart(x):\n",
    "    \"\"\"\n",
    "    Converts a tensor with last dimension in [angle, phase] to [a, jb] form\n",
    "    \"\"\"\n",
    "    amp = x[:,0].unsqueeze(-1)\n",
    "    phase = x[:,1].unsqueeze(-1)\n",
    "    return torch.cat((amp*torch.cos(phase), amp*torch.sin(phase)), dim=-1)\n",
    "\n",
    "def db_to_amp(x):\n",
    "    \"\"\"\n",
    "    Converts a pytorch tensor from decibels to amplitude\n",
    "    \"\"\"\n",
    "    return torch.pow(10, (0.5*x))\n",
    "\n",
    "def amp_to_db(x):\n",
    "    \"\"\"\n",
    "    Converts a pytorch tensor amplitude to decibels\n",
    "    \"\"\"\n",
    "    return taf.amplitude_to_DB(x, 20, -80, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#%%writefile AudioTransforms.py\n",
    "#from imports import *\n",
    "\n",
    "class Noise(object):\n",
    "    \"\"\" Adds a random noise file to the original signal at a random normally distributed amplitude\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_path, noise_sr=None, db_mean=-12, db_sd=3, use_cuda=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            noise_path (str|Path): path to noise files, or list of files\n",
    "            noise_sr (int): rate at which to resample noise files. If None, uses native sample rate.\n",
    "            db_mean (float|int): mean amplitude of noise w.r.t. speech signal in decibels (default: -12)\n",
    "            db_sd (float|int): standard deviation of noise amplitude in decibels (default: 3)\n",
    "        \"\"\"\n",
    "        if type(noise_path) is not list:\n",
    "            noise_path = list(noise_path.glob('*.wav'))\n",
    "            \n",
    "        self.noises, self.srs = zip(*[ta.load(x) for x in tqdm(noise_path, desc='Loading Noises...')])\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.noises = [x.cuda() for x in self.noises]\n",
    "            \n",
    "        if noise_sr:\n",
    "            self.noises = [ta.transforms.Resample(self.srs[i], noise_sr)(self.noises[i]) for i in \n",
    "                           tqdm(range(len(self.noises)), desc='Resampling Noises...')]\n",
    "            \n",
    "        self.db_dist = (db_mean, db_sd)\n",
    "        \n",
    "    def __call__(self, speech):\n",
    "        db = np.random.normal(self.db_dist[0], self.db_dist[1])\n",
    "        amp = lr.db_to_amplitude(db)\n",
    "        n = random.choice(self.noises)\n",
    "        if speech.shape[-1] < n.shape[-1]:\n",
    "            return speech + amp * n[:,:speech.shape[-1]]\n",
    "        else:\n",
    "            return speech[:,:n.shape[-1]] + amp * n\n",
    "\n",
    "class Reverb(object):\n",
    "    \"\"\" Adds a convolutional reverb to the speech from a randomly chosen impulse response\n",
    "        Crops the beginning of the impulse response to non-silent parts to maintain time-alignment of input and target\n",
    "    \"\"\"\n",
    "    def __init__(self, ir_path, ir_sr=None, ir_mono=True, use_cuda=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ir_path (str|Path): path to a directory of impulse responses or list of files\n",
    "            ir_sr (int): rate at which to resample impulse responses. if None (default) uses native sample rate.\n",
    "            ir_mono (bool): if true, loads only first channel of impulse response, else loads all channels\n",
    "        \"\"\"\n",
    "        if type(ir_path) is not list:\n",
    "            ir_path = list(ir_path.glob('*.wav'))\n",
    "            \n",
    "        self.irs, self.srs = zip(*[ta.load(x) for x in tqdm(ir_path, desc='Loading Impulse Responses...')])\n",
    "        \n",
    "        if ir_sr:\n",
    "            self.irs = [ta.transforms.Resample(self.srs[i], ir_sr)(self.irs[i]) for i in \n",
    "                        tqdm(range(len(self.irs)), desc='Resampling Impulse Responses...')]\n",
    "        if ir_mono:\n",
    "            self.irs = [x[0,:] for x in self.irs]\n",
    "            \n",
    "        if use_cuda:\n",
    "            self.irs = [x.cuda() for x in self.irs]\n",
    "            \n",
    "        # Crop beginning silence of IRS\n",
    "        crop_idxs = [x.argmax(-1) for x in self.irs]\n",
    "        self.irs = [x[crop_idxs[i]:].unsqueeze(0).unsqueeze(1) for i,x in enumerate(self.irs)]\n",
    "    \n",
    "    def __call__(self, speech):\n",
    "        ir = random.choice(self.irs)\n",
    "        if ir.shape[-1] < speech.shape[-1]:\n",
    "            padding = ir.shape[-1]\n",
    "            inputs, filters = speech.unsqueeze(0), ir.flip(-1)\n",
    "        else:\n",
    "            padding = speech.shape[-1]\n",
    "            inputs, filters = ir, speech.unsqueeze(0).flip(-1)\n",
    "            \n",
    "        return F.conv1d(inputs, filters, padding=padding)[0,:,:speech.shape[-1]].cpu()\n",
    "        \n",
    "        # TODO: replace this with torch.conv1d\n",
    "        #return torch.Tensor(np.convolve(speech.squeeze().numpy(), ir.squeeze().numpy(), 'same')).unsqueeze(0)\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\" Crop sample to fixed length starting at random position. Pads with zeros if sample not long enough.\n",
    "    \"\"\"\n",
    "    def __init__(self, length, no_rand=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            length (int): length of returned clips in samples\n",
    "            no_rand (bool): if true will always start at beginning of clip. (default: False)\n",
    "        \"\"\"\n",
    "        self.crop_len = length\n",
    "        self.no_rand = no_rand\n",
    "        \n",
    "    def __call__(self, speech):\n",
    "        if self.no_rand:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = random.randint(0, abs(speech.shape[-1]-self.crop_len))\n",
    "            \n",
    "        if speech.shape[-1] > self.crop_len:\n",
    "            return speech[:,start:start+self.crop_len]\n",
    "        else:\n",
    "            retval = torch.zeros((1,self.crop_len))\n",
    "            retval[:,0:speech.shape[-1]] = speech\n",
    "            return retval\n",
    "\n",
    "class LoadCrop(object):\n",
    "    \"\"\" Similar to RandomCrop, but acts on loading the signal to save disk bandwidth.\n",
    "        About 20x faster in testing when using a frame length of 2048.\n",
    "    \"\"\"\n",
    "    def __init__(self, length, no_rand=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            length (int): length of returned clips in samples\n",
    "            no_rand (bool): if true will always start at beginning of clip. (default: False)\n",
    "        \"\"\"\n",
    "        self.crop_len = length\n",
    "        self.no_rand = no_rand\n",
    "        \n",
    "    def __call__(self, fn):\n",
    "        try:\n",
    "            si,_ = ta.info(str(fn))\n",
    "\n",
    "            if si.length > self.crop_len and not self.no_rand:\n",
    "                start = random.randint(0, si.length-self.crop_len-1)\n",
    "            else:\n",
    "                start = 0\n",
    "\n",
    "            if si.length > (self.crop_len + start):\n",
    "                return ta.load(fn, num_frames=self.crop_len, offset=start)\n",
    "\n",
    "            # if problem happened above\n",
    "            speech,ssr = ta.load(fn)\n",
    "            if speech.shape[-1] < self.crop_len:\n",
    "                retval = torch.zeros((1,self.crop_len))\n",
    "                retval[:,0:speech.shape[-1]] = speech\n",
    "                return (retval, ssr)\n",
    "            else: # some other problem occurred reading a chunk of the file\n",
    "                return (speech[:,:self.crop_len], ssr)\n",
    "        except:\n",
    "            return (torch.zeros((1,self.crop_len)), 44100)\n",
    "        \n",
    "        \n",
    "class Normalize(object):\n",
    "    \"\"\" Normalizes a raw-audio waveform to the range specified\n",
    "    \"\"\"\n",
    "    def __init__(self, max_abs_val=1, eps=1e-12):\n",
    "        self.eps = eps\n",
    "        self.max_abs_val = max_abs_val\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self.max_abs_val * (x / (torch.max(torch.abs(x)) + self.eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#%%writefile DeReverbDataset.py\n",
    "#from imports import *\n",
    "\n",
    "class FMADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset for audio sequence to sequence tasks. \n",
    "    \"\"\"\n",
    "    def __init__(self, root_path, \n",
    "                 audio_path='fma_audio/', \n",
    "                 meta_path='fma_meta/',\n",
    "                 genres=None,\n",
    "                 loadcrop=None,\n",
    "                 tfms=ta.transforms.MelSpectrogram(sample_rate=44100, n_fft=4096)):\n",
    "        self.rp = Path(root_path)\n",
    "        self.audio_files = list((self.rp/audio_path).glob(\"**/*.mp3\"))\n",
    "        self.labels = pd.read_csv(self.rp/meta_path/\"raw_tracks.csv\")\n",
    "        self.labels.track_genres = self.labels.track_genres.apply(self.fix_genres)\n",
    "        self.gdf = pd.read_csv(self.rp/meta_path/\"genres.csv\")\n",
    "        self.tfms = tfms\n",
    "        \n",
    "        self.tlgenres = {}\n",
    "        self.topgs = []\n",
    "        for i,gid in enumerate(self.gdf.genre_id):\n",
    "            top = self.gdf['top_level'].iloc[i]\n",
    "            if top not in self.topgs:\n",
    "                self.topgs.append(top)\n",
    "            \n",
    "            self.tlgenres[gid] = {\"name\": self.gdf['title'].iloc[i], \n",
    "                                  \"tlg\": self.topgs.index(top)} \n",
    "            \n",
    "        # Filter audio files\n",
    "        self.audio_files = [x for x in self.audio_files if self.get_genre(x) is not None]\n",
    "            \n",
    "        if loadcrop:\n",
    "            self.loader = loadcrop\n",
    "        else:\n",
    "            self.loader = ta.load\n",
    "            \n",
    "    def fix_genres(self, genre_string):\n",
    "        \"\"\" Turns strings in genre dataframe into a single-genre dictionary\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return ast.literal_eval(genre_string)[0]\n",
    "        except:\n",
    "            #print(f\"couldn't fix genre for {genre_string}\")\n",
    "            return None\n",
    "        \n",
    "    def get_genre(self, af, ngs=16):\n",
    "        \"\"\" Utility function to get the genre as a one-hot tensor\n",
    "        \"\"\"\n",
    "        try:\n",
    "            g = int(self.labels[self.labels.track_id == int(af.parts[-1][:-4])].track_genres.iloc[0]['genre_id'])\n",
    "            topg = self.tlgenres[g][\"tlg\"]\n",
    "            assert topg < ngs, f\"genre {topg} > number of possible genres {ngs}\"\n",
    "            return (self.tlgenres[g][\"name\"], torch.tensor(topg))\n",
    "        except Exception as E:\n",
    "            #print(f\"no genre found for: {af.parts[-1]}\")\n",
    "            print(E)\n",
    "            return None\n",
    "    \n",
    "    def show(self, idx):\n",
    "        \"\"\" displays a spectrogram with track title and genre\n",
    "        \"\"\"\n",
    "        it = self.__getitem__(idx)\n",
    "        plt.imshow(torch.log10(it['audio'].squeeze(0).detach().flip(0)))\n",
    "        gname = it[\"genre\"]\n",
    "        title = self.labels.track_title[idx]\n",
    "        artist = self.labels.artist_name[idx]\n",
    "        plt.title(f\"{gname}: {title} by {artist}\")\n",
    "        plt.show()\n",
    "        display(Audio(self.audio_files[idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        afn = self.audio_files[idx]\n",
    "        try:\n",
    "            audio, sr = self.loader(afn)\n",
    "        except Exception as E:\n",
    "            print(E)\n",
    "            print(f\"problem loading {afn}\")\n",
    "            return {\"audio\": torch.zeros((1, 1)), \"genre\": \"none\", \"label\": 0}\n",
    "        \n",
    "        # Hacky conversion to mono\n",
    "        audio = audio[0,:].unsqueeze(0)\n",
    "        \n",
    "        if self.tfms:\n",
    "            audio = self.tfms(audio).detach()\n",
    "            \n",
    "        # TODO: load label here\n",
    "        name, label = self.get_genre(afn)\n",
    "            \n",
    "        sample =  {\"audio\": audio, \"genre\": name, \"label\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "datap = Path(\"/home/zach/Data/fma_medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tfms = ta.transforms.MelSpectrogram(sample_rate=44100, n_fft=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/home/zach/Data/fma_medium/fma_meta/raw_tracks.csv' does not exist: b'/home/zach/Data/fma_medium/fma_meta/raw_tracks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-caeb24b9f4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFMADataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloadcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLoadCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_rand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-67fe455cbfe9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_path, audio_path, meta_path, genres, loadcrop, tfms)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**/*.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"raw_tracks.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_genres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_genres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"genres.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_v2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_v2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_v2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_v2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_v2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/home/zach/Data/fma_medium/fma_meta/raw_tracks.csv' does not exist: b'/home/zach/Data/fma_medium/fma_meta/raw_tracks.csv'"
     ]
    }
   ],
   "source": [
    "dataset = FMADataset(datap, tfms=tfms, loadcrop=LoadCrop(5*44100, no_rand=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_len = int(0.8*len(dataset))\n",
    "train_ds, valid_ds = torch.utils.data.random_split(dataset, [train_len, len(dataset)-train_len])\n",
    "train_dl, valid_dl = [DataLoader(ds, batch_size=16, shuffle=True, num_workers=6) for ds in [train_ds, valid_ds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dataset.show(random.choice(range(dataset.__len__())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8584e6c1ab16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "rn = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Switch number of classes and number of image channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rn._modules['fc'] = nn.Linear(512, 16)\n",
    "rn._modules['conv1'] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6978e-01, -4.2887e-01, -2.1282e-01,  1.0640e-02, -8.6547e-02,\n",
       "         -6.4375e-02,  4.2154e-01, -5.8184e-01, -4.5799e-01,  6.5946e-01,\n",
       "          8.3857e-02, -2.5860e-01,  4.6708e-02, -6.1128e-01,  1.7766e-01,\n",
       "         -5.8930e-01],\n",
       "        [-2.5801e-01, -1.3201e-01,  4.8451e-02, -2.0228e-02,  9.8090e-02,\n",
       "          1.5222e-02,  1.0546e-01, -3.1590e-01, -2.6696e-01,  2.2369e-02,\n",
       "         -2.9770e-01, -5.8572e-02,  6.4094e-02, -2.6286e-01, -7.8059e-02,\n",
       "         -6.9768e-01],\n",
       "        [ 2.5569e-01,  1.5021e-01, -5.0945e-01, -2.2771e-01, -4.8395e-01,\n",
       "         -6.0828e-02,  7.6227e-01, -6.5522e-01,  7.2730e-02,  1.4578e-01,\n",
       "         -2.8237e-02, -3.7428e-01, -7.6022e-01, -3.8594e-01, -6.1625e-01,\n",
       "         -9.0716e-01],\n",
       "        [ 2.7288e-01,  4.8921e-02, -3.9941e-01,  1.8810e-01, -8.5964e-01,\n",
       "          1.3887e-01,  4.7782e-01, -4.9645e-01, -4.5062e-01,  2.1465e-01,\n",
       "         -4.1137e-01, -5.6194e-02,  1.3425e-01, -3.4578e-01, -6.8314e-02,\n",
       "         -4.9233e-01],\n",
       "        [ 5.7959e-01,  3.0822e-01, -2.1464e-01, -4.1418e-01, -4.1080e-01,\n",
       "          2.4653e-01,  3.6704e-01, -1.1097e+00, -1.5751e-01,  5.0880e-01,\n",
       "         -4.6165e-01, -4.2620e-01,  2.3191e-01, -4.7139e-02,  5.0790e-04,\n",
       "         -1.0343e+00],\n",
       "        [ 5.2548e-01, -3.3708e-01, -8.1993e-01, -4.5139e-01, -1.6027e+00,\n",
       "          7.2285e-01,  7.0870e-01, -1.4177e+00,  1.3254e+00,  9.6893e-01,\n",
       "         -6.6816e-01, -3.0857e-01, -7.0935e-01, -6.0545e-01,  1.6503e-01,\n",
       "          6.2838e-02],\n",
       "        [ 2.7332e-01,  2.1070e-01, -3.1244e-02, -2.0543e-01, -5.1817e-01,\n",
       "          3.7419e-01,  3.6722e-01, -4.6851e-01, -8.6345e-02,  3.6772e-01,\n",
       "         -1.0321e-01, -1.5935e-01, -1.8233e-01, -2.2303e-01, -4.6308e-01,\n",
       "         -6.6395e-01],\n",
       "        [ 9.5854e-02, -9.6072e-02, -6.5782e-01, -3.1386e-01, -4.0595e-02,\n",
       "         -3.3291e-01,  9.7880e-02, -4.1967e-01,  2.5144e-01,  1.0974e-02,\n",
       "         -4.5574e-01, -5.5994e-01, -2.1182e-01, -3.4875e-01,  1.7654e-01,\n",
       "         -8.3387e-01],\n",
       "        [ 3.6934e-01, -4.1940e-01,  4.7268e-02, -5.0981e-01, -2.9115e-01,\n",
       "          3.5681e-01,  1.2343e-01, -6.7086e-01, -6.7935e-01,  9.8109e-01,\n",
       "          2.9922e-01, -3.6029e-01, -3.5166e-01, -2.6844e-01, -1.3144e+00,\n",
       "         -1.4442e+00],\n",
       "        [ 6.6953e-01, -2.6518e-01, -2.9525e-01, -3.3538e-01, -9.0295e-01,\n",
       "         -3.6192e-01,  9.4874e-01, -9.5304e-01,  2.3680e-01,  2.4393e-01,\n",
       "         -6.3485e-01, -6.4590e-01, -2.6641e-01, -2.7081e-01,  9.2405e-02,\n",
       "         -4.7026e-01],\n",
       "        [ 3.2983e-03,  1.0353e-01, -2.5064e-02, -2.2957e-01, -1.6729e-01,\n",
       "          2.8095e-01,  4.2130e-01, -8.5104e-01,  2.4838e-01,  3.2669e-01,\n",
       "          2.7965e-02,  3.0880e-01, -5.0701e-01,  2.1831e-01, -4.6432e-01,\n",
       "         -4.5155e-01],\n",
       "        [-3.9556e-01, -1.3123e-01, -1.1304e-01, -1.2320e-01, -1.0205e-01,\n",
       "         -1.1567e-01,  1.0085e+00, -5.7026e-01, -1.3403e-01,  3.6172e-01,\n",
       "         -9.3724e-01, -3.0358e-01, -2.6259e-01, -3.8762e-01, -5.2234e-01,\n",
       "         -9.2007e-01],\n",
       "        [ 2.7250e-01, -6.8088e-02, -1.0507e+00, -1.0435e+00, -3.1890e-01,\n",
       "          7.1498e-01, -1.2092e-01, -1.1267e+00,  2.9440e-03,  7.4144e-01,\n",
       "          4.9836e-01,  5.3977e-01, -6.0820e-01,  2.1191e-02, -5.3333e-01,\n",
       "         -1.0521e+00],\n",
       "        [ 5.3301e-02, -1.5594e-01, -2.1352e-01,  4.9183e-02, -4.6916e-01,\n",
       "          4.4869e-01,  3.1379e-01, -2.0837e-01, -1.7646e-02,  8.5242e-01,\n",
       "          2.4284e-01, -5.1602e-01, -7.6233e-01, -8.1929e-02, -2.5676e-01,\n",
       "         -8.0274e-01],\n",
       "        [-5.5716e-01, -7.1505e-02, -2.3431e-02,  1.2509e-01, -3.6690e-01,\n",
       "          2.3760e-01,  3.4575e-01, -6.5625e-01, -8.9034e-02,  1.6019e-01,\n",
       "         -4.5369e-01,  8.3826e-02, -1.5948e-01, -2.5243e-01, -9.2128e-02,\n",
       "         -5.2220e-01],\n",
       "        [ 3.2163e-01, -3.9957e-02, -2.9311e-02, -2.8566e-02, -5.5853e-01,\n",
       "          1.6803e-01,  3.5712e-01, -1.0215e+00, -6.4162e-02,  8.7197e-01,\n",
       "         -1.7946e-01, -6.7942e-01, -9.6178e-01, -6.5007e-01, -4.2637e-01,\n",
       "         -4.5183e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn.forward(next(iter(train_dl))[\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0123e74c2a94bbaac0c9acfbf285e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f37617dea1490387b3904b5cdcecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training example', max=1250.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 4.\nOriginal Traceback (most recent call last):\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 431 and 140 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-16dbc7fe52e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training example\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 4.\nOriginal Traceback (most recent call last):\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 431 and 140 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "train_ls = []\n",
    "valid_ls = []\n",
    "\n",
    "m = rn\n",
    "m = m.cuda()\n",
    "optim = torch.optim.Adam(params=m.parameters(), lr=2e-3)\n",
    "critereon = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in tqdm(range(n_epochs), \"epoch\"):\n",
    "    m.train()\n",
    "    for it in tqdm(train_dl, \"training example\"):\n",
    "        audio, label = it[\"audio\"], it[\"label\"]\n",
    "        m.zero_grad()\n",
    "        out = m(audio.cuda())\n",
    "        l = critereon(out, label.cuda())\n",
    "        train_ls.append(l.detach().cpu())\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        for it in tqdm(valid_dl, \"validation example\"):\n",
    "            audio, label = it[\"audio\"], it[\"label\"]\n",
    "            out = m(audio.cuda())\n",
    "            l = critereon(out, label.cuda())\n",
    "            valid_ls.append(l.detach().cpu())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b86ac28a1a42eabc506228a57e9824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 131 and 431 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-9e99a804c120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/zach/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 131 and 431 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(train_dl):\n",
    "    try:\n",
    "        audio, label = batch[\"audio\"], batch[\"label\"]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ambient', tensor(14))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_genre(Path(\"/home/zach/Data/fma_medium/fma_audio/080/080391.mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220500])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoadCrop(5*44100, no_rand=True)(\"/home/zach/Data/fma_medium/fma_audio/080/080391.mp3\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.1260e-03,\n",
       "          -3.1140e-03, -7.7464e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.2293e-02,\n",
       "           5.8719e-03,  4.3727e-05]]), 44100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoadCrop(5*44100, no_rand=True)(\"/home/zach/Data/fma_medium/fma_audio/000/000002.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zach/Data/fma_medium/fma_audio/000/000002.mp3'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/home/zach/Data/fma_medium/fma_audio/000/000002.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
